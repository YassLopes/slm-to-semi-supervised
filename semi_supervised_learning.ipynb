{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning para Classificação de Sintomas Médicos\n",
    "\n",
    "Este notebook demonstra como implementar aprendizado semi-supervisionado para melhorar a classificação de sintomas médicos em diagnósticos, usando o dataset \"gretelai/symptom_to_diagnosis\" do HuggingFace.\n",
    "\n",
    "Implementamos a técnica de pseudo-rotulagem (pseudo-labeling) para aproveitar dados não rotulados e melhorar o desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalação de Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependências necessárias\n",
    "!pip install torch transformers datasets scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, ConcatDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union, Optional\n",
    "\n",
    "# Verificar disponibilidade de GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funções Utilitárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Configura sementes aleatórias para reprodutibilidade.\n",
    "    \n",
    "    Args:\n",
    "        seed: Valor da semente\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Determina o dispositivo disponível (GPU ou CPU).\n",
    "    \n",
    "    Returns:\n",
    "        device: Dispositivo PyTorch\n",
    "    \"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def print_dataset_examples(dataset, num_examples=3):\n",
    "    \"\"\"\n",
    "    Imprime exemplos do dataset para inspeção.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset a ser inspecionado\n",
    "        num_examples: Número de exemplos a serem exibidos\n",
    "    \"\"\"\n",
    "    print(\"\\nExemplos do dataset:\")\n",
    "    for i in range(min(num_examples, len(dataset['train']))):\n",
    "        print(f\"Exemplo {i+1}:\")\n",
    "        print(f\"Sintomas: {dataset['train'][i]['input_text']}\")\n",
    "        print(f\"Diagnóstico: {dataset['train'][i]['output_text']}\")\n",
    "        print()\n",
    "\n",
    "def print_comparison_results(eval_results, final_eval_results):\n",
    "    \"\"\"\n",
    "    Imprime uma comparação dos resultados antes e depois do treinamento semi-supervisionado.\n",
    "    \n",
    "    Args:\n",
    "        eval_results: Resultados da avaliação após treinamento supervisionado\n",
    "        final_eval_results: Resultados da avaliação após treinamento semi-supervisionado\n",
    "    \"\"\"\n",
    "    print(\"\\nComparação dos resultados:\")\n",
    "    print(f\"Acurácia (supervisionado): {eval_results['eval_accuracy']:.4f}\")\n",
    "    print(f\"Acurácia (semi-supervisionado): {final_eval_results['eval_accuracy']:.4f}\")\n",
    "    print(f\"Melhoria na acurácia: {final_eval_results['eval_accuracy'] - eval_results['eval_accuracy']:.4f}\")\n",
    "    \n",
    "    print(f\"F1-score (supervisionado): {eval_results['eval_f1']:.4f}\")\n",
    "    print(f\"F1-score (semi-supervisionado): {final_eval_results['eval_f1']:.4f}\")\n",
    "    print(f\"Melhoria no F1-score: {final_eval_results['eval_f1'] - eval_results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Funções de Processamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_symptom_diagnosis_dataset(max_samples=None):\n",
    "    \"\"\"\n",
    "    Carrega o dataset de sintomas e diagnósticos.\n",
    "    \n",
    "    Args:\n",
    "        max_samples: Se especificado, limita o número de amostras para teste rápido\n",
    "        \n",
    "    Returns:\n",
    "        dataset: Dataset carregado\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"gretelai/symptom_to_diagnosis\")\n",
    "    \n",
    "    if max_samples and len(dataset['train']) > max_samples:\n",
    "        dataset['train'] = dataset['train'].select(range(max_samples))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def prepare_labels(dataset):\n",
    "    \"\"\"\n",
    "    Prepara os rótulos e retorna um encoder para os diagnósticos.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset contendo rótulos em 'output_text'\n",
    "        \n",
    "    Returns:\n",
    "        label_encoder: O encoder treinado nos rótulos\n",
    "        num_labels: Número de classes únicas\n",
    "    \"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels = dataset['train']['output_text']\n",
    "    label_encoder.fit(all_labels)\n",
    "    num_labels = len(label_encoder.classes_)\n",
    "    \n",
    "    return label_encoder, num_labels\n",
    "\n",
    "def tokenize_dataset(dataset, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokeniza o dataset usando o tokenizer fornecido.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset a ser tokenizado\n",
    "        tokenizer: Tokenizer a ser usado\n",
    "        \n",
    "    Returns:\n",
    "        tokenized_dataset: Dataset tokenizado\n",
    "    \"\"\"\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"input_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    return dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "def create_semi_supervised_split(tokenized_dataset, dataset, label_encoder, tokenizer, labeled_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Cria divisões de dados para aprendizado semi-supervisionado.\n",
    "    \n",
    "    Args:\n",
    "        tokenized_dataset: Dataset tokenizado\n",
    "        dataset: Dataset original com rótulos\n",
    "        label_encoder: Encoder para os rótulos\n",
    "        tokenizer: Tokenizer para processar os textos\n",
    "        labeled_ratio: Fração de dados rotulados a serem usados\n",
    "        \n",
    "    Returns:\n",
    "        labeled_dataset: TensorDataset com dados rotulados\n",
    "        unlabeled_dataset: TensorDataset com dados não rotulados\n",
    "        unlabeled_indices: Índices dos dados não rotulados\n",
    "        labeled_indices: Índices dos dados rotulados\n",
    "        unlabeled_tokenized: Tokens dos dados não rotulados\n",
    "    \"\"\"\n",
    "    # Embaralhar os índices\n",
    "    train_indices = list(range(len(tokenized_dataset[\"train\"])))\n",
    "    random.shuffle(train_indices)\n",
    "    \n",
    "    # Dividir em conjunto rotulado e não-rotulado\n",
    "    num_labeled = int(labeled_ratio * len(train_indices))\n",
    "    labeled_indices = train_indices[:num_labeled]\n",
    "    unlabeled_indices = train_indices[num_labeled:]\n",
    "    \n",
    "    # Função para codificar os rótulos\n",
    "    def encode_labels(labels):\n",
    "        return label_encoder.transform(labels)\n",
    "    \n",
    "    # Criar conjuntos de dados rotulados\n",
    "    labeled_texts = [tokenized_dataset[\"train\"][i][\"input_text\"] for i in labeled_indices]\n",
    "    labeled_tokenized = tokenizer(labeled_texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    labeled_labels = [dataset[\"train\"][i][\"output_text\"] for i in labeled_indices]\n",
    "    \n",
    "    # Converter rótulos para long\n",
    "    labeled_encoded_labels = torch.tensor(encode_labels(labeled_labels), dtype=torch.long)\n",
    "    \n",
    "    labeled_dataset = TensorDataset(\n",
    "        labeled_tokenized[\"input_ids\"],\n",
    "        labeled_tokenized[\"attention_mask\"],\n",
    "        labeled_encoded_labels\n",
    "    )\n",
    "    \n",
    "    # Criar conjuntos de dados não-rotulados\n",
    "    unlabeled_texts = [tokenized_dataset[\"train\"][i][\"input_text\"] for i in unlabeled_indices]\n",
    "    unlabeled_tokenized = tokenizer(unlabeled_texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    \n",
    "    unlabeled_dataset = TensorDataset(\n",
    "        unlabeled_tokenized[\"input_ids\"],\n",
    "        unlabeled_tokenized[\"attention_mask\"]\n",
    "    )\n",
    "    \n",
    "    return labeled_dataset, unlabeled_dataset, unlabeled_indices, labeled_indices, unlabeled_tokenized\n",
    "\n",
    "def split_train_val(dataset, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Divide um dataset em conjuntos de treino e validação.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset a ser dividido\n",
    "        val_ratio: Fração de dados para validação\n",
    "        \n",
    "    Returns:\n",
    "        train_dataset, val_dataset: Datasets de treino e validação\n",
    "    \"\"\"\n",
    "    val_size = int(len(dataset) * val_ratio)\n",
    "    train_size = len(dataset) - val_size\n",
    "    return random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Funções de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(model_name=\"distilbert/distilbert-base-uncased\"):\n",
    "    \"\"\"\n",
    "    Obtém o tokenizer para o modelo especificado.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Nome do modelo pré-treinado\n",
    "        \n",
    "    Returns:\n",
    "        tokenizer: Tokenizer configurado\n",
    "    \"\"\"\n",
    "    return AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def get_model(model_name=\"distilbert/distilbert-base-uncased\", num_labels=22):\n",
    "    \"\"\"\n",
    "    Cria e retorna o modelo de classificação.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Nome do modelo pré-treinado\n",
    "        num_labels: Número de classes para classificação\n",
    "        \n",
    "    Returns:\n",
    "        model: Modelo de classificação configurado\n",
    "    \"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    return model\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Calcula as métricas de avaliação para o modelo.\n",
    "    \n",
    "    Args:\n",
    "        pred: Saída de predição do modelo\n",
    "        \n",
    "    Returns:\n",
    "        metrics: Dicionário com métricas calculadas\n",
    "    \"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "def generate_pseudo_labels(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Gera pseudo-rótulos para dados não rotulados.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        dataloader: DataLoader com dados não rotulados\n",
    "        device: Dispositivo (CPU ou GPU)\n",
    "        \n",
    "    Returns:\n",
    "        pseudo_labels: Lista de pseudo-rótulos gerados\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    pseudo_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            pseudo_labels.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    return pseudo_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Funções de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForTextClassification:\n",
    "    \"\"\"\n",
    "    Collator personalizado para classificação de textos que lida com nossos TensorDatasets.\n",
    "    \"\"\"\n",
    "    def __call__(self, features):\n",
    "        \"\"\"\n",
    "        Agrupa elementos em um batch.\n",
    "        \n",
    "        Args:\n",
    "            features: Lista de elementos do dataset\n",
    "            \n",
    "        Returns:\n",
    "            Batch de dados formatado corretamente\n",
    "        \"\"\"\n",
    "        # Cada feature é (input_ids, attention_mask, label) de um TensorDataset\n",
    "        if isinstance(features[0], tuple):\n",
    "            input_ids = torch.stack([f[0] for f in features])\n",
    "            attention_mask = torch.stack([f[1] for f in features])\n",
    "            \n",
    "            if len(features[0]) > 2:  # Se tiver rótulos\n",
    "                # Garantir que os rótulos sejam do tipo long\n",
    "                labels = torch.stack([f[2] for f in features]).long()\n",
    "                return {\n",
    "                    \"input_ids\": input_ids,\n",
    "                    \"attention_mask\": attention_mask,\n",
    "                    \"labels\": labels\n",
    "                }\n",
    "            \n",
    "            return {\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "            }\n",
    "        \n",
    "        # Fallback para o comportamento padrão\n",
    "        batch = {k: torch.stack([f[k] for f in features]) for k in features[0].keys()}\n",
    "        \n",
    "        # Garantir que os rótulos sejam long se existirem\n",
    "        if \"labels\" in batch:\n",
    "            batch[\"labels\"] = batch[\"labels\"].long()\n",
    "            \n",
    "        return batch\n",
    "\n",
    "def get_training_args(output_dir, num_train_epochs=3, batch_size=16, eval_batch_size=64):\n",
    "    \"\"\"\n",
    "    Configura os argumentos de treinamento.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Diretório para salvar resultados\n",
    "        num_train_epochs: Número de épocas de treinamento\n",
    "        batch_size: Tamanho do batch para treinamento\n",
    "        eval_batch_size: Tamanho do batch para avaliação\n",
    "        \n",
    "    Returns:\n",
    "        training_args: Argumentos de treinamento configurados\n",
    "    \"\"\"\n",
    "    # Usar apenas argumentos essenciais básicos\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=eval_batch_size,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "    )\n",
    "    \n",
    "    return training_args\n",
    "\n",
    "def train_supervised_model(model, tokenizer, labeled_train_dataset, labeled_val_dataset, compute_metrics, output_dir=\"./results_supervised\"):\n",
    "    \"\"\"\n",
    "    Treina o modelo usando apenas dados rotulados (aprendizado supervisionado).\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a ser treinado\n",
    "        tokenizer: Tokenizer usado\n",
    "        labeled_train_dataset: Dataset de treino rotulado\n",
    "        labeled_val_dataset: Dataset de validação\n",
    "        compute_metrics: Função para calcular métricas\n",
    "        output_dir: Diretório para salvar resultados\n",
    "        \n",
    "    Returns:\n",
    "        trainer: Objeto Trainer treinado\n",
    "        eval_results: Resultados da avaliação\n",
    "    \"\"\"\n",
    "    training_args = get_training_args(output_dir)\n",
    "    data_collator = DataCollatorForTextClassification()\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=labeled_train_dataset,\n",
    "        eval_dataset=labeled_val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,  # Usar o collator personalizado\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    \n",
    "    return trainer, eval_results\n",
    "\n",
    "def train_semi_supervised_model(model, pseudo_labeled_dataset, labeled_train_dataset, labeled_val_dataset, compute_metrics, output_dir=\"./results_semi_supervised\"):\n",
    "    \"\"\"\n",
    "    Treina o modelo usando dados rotulados e pseudo-rotulados (aprendizado semi-supervisionado).\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo pré-treinado com dados rotulados\n",
    "        pseudo_labeled_dataset: Dataset com pseudo-rótulos\n",
    "        labeled_train_dataset: Dataset de treino rotulado\n",
    "        labeled_val_dataset: Dataset de validação\n",
    "        compute_metrics: Função para calcular métricas\n",
    "        output_dir: Diretório para salvar resultados\n",
    "        \n",
    "    Returns:\n",
    "        trainer: Objeto Trainer treinado\n",
    "        eval_results: Resultados da avaliação\n",
    "    \"\"\"\n",
    "    # Combinar dados rotulados com pseudo-rotulados\n",
    "    combined_dataset = ConcatDataset([labeled_train_dataset, pseudo_labeled_dataset])\n",
    "    \n",
    "    # Configurar treinamento\n",
    "    training_args = get_training_args(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=2  # Menos épocas para o treinamento semi-supervisionado\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForTextClassification()\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=combined_dataset,\n",
    "        eval_dataset=labeled_val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,  # Usar o collator personalizado\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    \n",
    "    return trainer, eval_results\n",
    "\n",
    "def create_pseudo_labeled_dataset(unlabeled_tokenized, pseudo_labels):\n",
    "    \"\"\"\n",
    "    Cria um dataset com pseudo-rótulos.\n",
    "    \n",
    "    Args:\n",
    "        unlabeled_tokenized: Tensores tokenizados de dados não rotulados\n",
    "        pseudo_labels: Lista de pseudo-rótulos gerados pelo modelo\n",
    "        \n",
    "    Returns:\n",
    "        pseudo_labeled_dataset: TensorDataset com dados pseudo-rotulados\n",
    "    \"\"\"\n",
    "    return TensorDataset(\n",
    "        unlabeled_tokenized[\"input_ids\"],\n",
    "        unlabeled_tokenized[\"attention_mask\"],\n",
    "        torch.tensor(pseudo_labels, dtype=torch.long)  # Garantir que os rótulos sejam do tipo long\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Execução do Fluxo de Trabalho de Aprendizado Semi-Supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros configuráveis\n",
    "MAX_SAMPLES = 500  # Limite de amostras para execução rápida (None para usar todo o dataset)\n",
    "LABELED_RATIO = 0.2  # Proporção de dados rotulados (20%)\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"  # Modelo pré-treinado\n",
    "OUTPUT_DIR = \"./results\"  # Diretório para salvar resultados\n",
    "SEED = 42  # Semente para reprodutibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar sementes para reprodutibilidade\n",
    "set_seed(SEED)\n",
    "\n",
    "# Determinar dispositivo (GPU ou CPU)\n",
    "device = get_device()\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Carregar o dataset\n",
    "print(\"Carregando dataset...\")\n",
    "dataset = load_symptom_diagnosis_dataset(max_samples=MAX_SAMPLES)\n",
    "print(f\"Dataset carregado com {len(dataset['train'])} amostras de treino\")\n",
    "\n",
    "# Mostrar alguns exemplos\n",
    "print_dataset_examples(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar os rótulos (diagnósticos)\n",
    "label_encoder, num_labels = prepare_labels(dataset)\n",
    "print(f\"Número de diagnósticos possíveis: {num_labels}\")\n",
    "print(f\"Diagnósticos: {label_encoder.classes_}\")\n",
    "\n",
    "# Inicializar tokenizer e modelo\n",
    "tokenizer = get_tokenizer(MODEL_NAME)\n",
    "\n",
    "# Tokenizar o dataset\n",
    "tokenized_dataset = tokenize_dataset(dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar divisão semi-supervisionada\n",
    "labeled_dataset, unlabeled_dataset, unlabeled_indices, labeled_indices, unlabeled_tokenized = create_semi_supervised_split(\n",
    "    tokenized_dataset, dataset, label_encoder, tokenizer, labeled_ratio=LABELED_RATIO\n",
    ")\n",
    "\n",
    "print(f\"Usando {len(labeled_indices)} amostras rotuladas e {len(unlabeled_indices)} não-rotuladas\")\n",
    "\n",
    "# Dividir dados rotulados em treino e validação\n",
    "labeled_train_dataset, labeled_val_dataset = split_train_val(labeled_dataset)\n",
    "\n",
    "print(f\"Conjunto de treino rotulado: {len(labeled_train_dataset)} amostras\")\n",
    "print(f\"Conjunto de validação: {len(labeled_val_dataset)} amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o modelo\n",
    "model = get_model(MODEL_NAME, num_labels=num_labels)\n",
    "model.to(device)\n",
    "\n",
    "# FASE 1: Treinamento supervisionado com dados rotulados\n",
    "print(\"\\nTreinando modelo inicial com dados rotulados...\")\n",
    "supervised_trainer, eval_results = train_supervised_model(\n",
    "    model, tokenizer, labeled_train_dataset, labeled_val_dataset, \n",
    "    compute_metrics, output_dir=f\"{OUTPUT_DIR}/supervised\"\n",
    ")\n",
    "\n",
    "print(f\"\\nResultados após treinamento supervisionado:\")\n",
    "print(f\"Acurácia: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-score: {eval_results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASE 2: Pseudo-rotulagem\n",
    "print(\"\\nIniciando fase de pseudo-rotulagem...\")\n",
    "\n",
    "# Criar DataLoader para dados não rotulados\n",
    "unlabeled_dataloader = DataLoader(\n",
    "    unlabeled_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Gerar pseudo-rótulos com o modelo treinado\n",
    "pseudo_labels = generate_pseudo_labels(model, unlabeled_dataloader, device)\n",
    "\n",
    "# Criar dataset com pseudo-rótulos\n",
    "pseudo_labeled_dataset = create_pseudo_labeled_dataset(unlabeled_tokenized, pseudo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASE 3: Treinamento semi-supervisionado\n",
    "print(\"\\nTreinando modelo com dataset combinado (rotulado + pseudo-rotulado)...\")\n",
    "semi_supervised_trainer, final_eval_results = train_semi_supervised_model(\n",
    "    model, pseudo_labeled_dataset, labeled_train_dataset, labeled_val_dataset, \n",
    "    compute_metrics, output_dir=f\"{OUTPUT_DIR}/semi_supervised\"\n",
    ")\n",
    "\n",
    "print(f\"\\nResultados após treinamento semi-supervisionado:\")\n",
    "print(f\"Acurácia: {final_eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-score: {final_eval_results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar resultados\n",
    "print_comparison_results(eval_results, final_eval_results)\n",
    "\n",
    "print(\"\\nDemonstração de aprendizado semi-supervisionado concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusão\n",
    "\n",
    "Neste notebook, demonstramos como implementar o aprendizado semi-supervisionado usando a técnica de pseudo-rotulagem para classificação de textos médicos. O processo envolveu:\n",
    "\n",
    "1. Treinar um modelo inicial com uma pequena porção de dados rotulados (20%)\n",
    "2. Usar este modelo para gerar \"pseudo-rótulos\" para os dados não rotulados (80%)\n",
    "3. Treinar um novo modelo combinando os dados rotulados originais com os dados pseudo-rotulados\n",
    "4. Comparar o desempenho dos modelos antes e depois do uso de dados pseudo-rotulados\n",
    "\n",
    "Os resultados mostram que, mesmo com uma quantidade limitada de dados rotulados, podemos aproveitar dados não rotulados para melhorar o desempenho do modelo através do aprendizado semi-supervisionado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
